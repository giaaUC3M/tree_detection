{"cells":[{"cell_type":"markdown","metadata":{"id":"Z1eCfrEFeZT-"},"source":["# INSTALLS & IMPORTS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9RDjBPbuNSsJ","vscode":{"languageId":"python"}},"outputs":[],"source":["#DEEPFOREST\n","!pip install DeepForest==0.3.8\n","!pip install tensorflow-gpu==1.14.0 # Para usar GPU\n","#it is necessary to uninstall and reinstall numpy due to a version compatibility problem.\n","!pip uninstall numpy # ASK FOR A YES\n","!pip install numpy\n","# DATA PROCESSING\n","!apt install gdal-bin python3-gdal\n","!apt-get install python-numpy python-scipy -y # Install numpy and scipy\n","!pip install pyshp # Shapefile\n","!pip install fiona==1.7\n","!pip install rasterio\n","!pip install pyproj\n","# ANALYSIS OF RESULTS\n","!pip install plotly==4.14.3 # Instala en la máquina virtual Plot.ly\n","!pip install -U kaleido     # Instala la librería que exporta las figuras a imágenes\n","!pip install pyyaml==5.4.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4454,"status":"ok","timestamp":1655279754331,"user":{"displayName":"LAZARO FORNIS HERRANZ","userId":"12453935234529602211"},"user_tz":-120},"id":"fG_p-sCSN64k","outputId":"932b5e77-a82e-48ac-8860-01b2b0e8f781","vscode":{"languageId":"python"}},"outputs":[],"source":["# IMPORTS DEEPFOREST\n","# BEFORE, RESTART RUNTIME\n","import numpy as np\n","import os\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from deepforest import deepforest\n","from deepforest import get_data\n","from deepforest import utilities\n","from deepforest import preprocess\n","import pandas as pd\n","\n","# IMPORTS DATA PROCESSING\n","import gdal\n","import os\n","from osgeo import osr, ogr, gdal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import cv2\n","from skimage import io\n","from PIL import Image \n","import matplotlib.pylab as plt\n","from osgeo import ogr\n","from shapely.geometry import Polygon\n","import math\n","!pip install fiona\n","import fiona\n","from fiona.crs import from_epsg\n","from shapely.geometry import MultiPolygon, Polygon, mapping\n","import matplotlib.pyplot as plt\n","from descartes import PolygonPatch\n","import os\n","import rasterio\n","import rasterio.mask\n","import csv\n","#IMPORTS ANALYSIS OF RESULTS\n","# Plotly\n","#from IPython.display import Image # to display images\n","import plotly       # Check that Plot.ly version is correct (prev versions than 4.14.3 do not use Kaleido)\n","plotly.__version__\n","import plotly.graph_objects as go # Se importa la librería\n","import plotly.express as px                         # Cosas de plotly generales. Como los colores\n","from plotly.offline import iplot, init_notebook_mode\n","from plotly.subplots import make_subplots\n","import plotly.graph_objs as go              # Para generar las figuras y los charts\n","import plotly.io as pio                     # Interfaz para guardar en SVG\n","import math\n","from pyproj import Geod\n","from shapely import wkt\n","# Prepara los símbolos y colores\n","from plotly.validators.scatter.marker import SymbolValidator\n","\n","#IMPORTS ACCESO A COLAB\n","from google.colab import output # Permite limpiar el log de Colab cada X tiempo\n","from google.colab import drive # acceso a ficheros de Drive\n","from google.colab import files # descargar ficheros generados\n","import glob     # to access Google Drive files\n","import os       # tratar nombres de ficheros y carpetas\n","drive.mount('/content/drive')\n","# Definir rutas\n","path      = \"/content/drive/MyDrive/tree_detection/Net_Trained_With_LiDAR_Detections\"   # Base. Según la cuenta será una u otra.  \n","# Cambia a la carpeta\n","%cd {path}\n","#!ls                # Muestra los ficheros para comprobar que la carpeta es correcta\n","\n","tif_image      = 'Orthophoto_Colmenarejo_Train'               # Fichero original\n","fileName=tif_image\n","fileExtension  = '.tif'                 # Extensión del fichero"]},{"cell_type":"markdown","metadata":{"id":"XO8Bb9Qfeeif"},"source":["# Read datasets SHP LiDAR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqwowUTb35jm","vscode":{"languageId":"python"}},"outputs":[],"source":["#################\n","def world_to_pixel(geo_matrix, x, y):\n","    \"\"\"\n","    Uses a gdal geomatrix (gdal.GetGeoTransform()) to calculate\n","    the pixel location of a geospatial coordinate\n","    \"\"\"\n","    ul_x   = geo_matrix[0]\n","    ul_y   = geo_matrix[3]\n","    x_dist = geo_matrix[1]\n","    y_dist = geo_matrix[5]\n","    pixel  =  int((x - ul_x) / x_dist)\n","    line   = -int((ul_y - y) / y_dist)\n","    return pixel, line\n","\n","#################\n","def pixel_to_world(geo_matrix, x, y):\n","    ul_x = geo_matrix[0]\n","    ul_y = geo_matrix[3]\n","    x_dist = geo_matrix[1]\n","    y_dist = geo_matrix[5]\n","    _x = x * x_dist + ul_x\n","    _y = y * y_dist + ul_y\n","    return _x, _y\n","\n","#################\n","def build_transform_inverse(dataset, EPSG):\n","    source = osr.SpatialReference(wkt=dataset.GetProjection())\n","    target = osr.SpatialReference()\n","    target.ImportFromEPSG(EPSG)\n","    return osr.CoordinateTransformation(source, target)\n","\n","#################\n","def find_spatial_coordinate_from_pixel(dataset, transform, x, y):\n","    world_x, world_y = pixel_to_world(dataset.GetGeoTransform(), x, y)\n","    point = ogr.Geometry(ogr.wkbPoint)\n","    point.AddPoint(world_x, world_y)\n","    point.Transform(transform)\n","    return point.GetX(), point.GetY()\n","\n","#################\n","# La ortofoto tiene su lat-lon predefinido. \n","# Esta función recibe una Lat Lon esquina arriba izq y abajo der y te devuelve qué píxeles correponden a dichos lugares\n","def getTIFcornerPoints(fileName, LatAI, LonAI, LatAD, LonAD):\n","    fileExtension = \".tif\"\n","    dem = gdal.Open(fileName+fileExtension)\n","    xmin, res, rot1, ymax, px_h, rot2 = dem.GetGeoTransform() # get coordinates of upper left corner\n","\n","    # Extraer el EPSG que modela las coordenadas\n","    EPSG   = osr.SpatialReference(wkt=dem.GetProjection()).GetAttrValue('AUTHORITY',1)\n","    source = osr.SpatialReference()\n","    source.ImportFromEPSG(int(EPSG))\n","    # Transformación a WGS84\n","    wgs84 = osr.SpatialReference()\n","    wgs84.ImportFromEPSG(4326)\n","    transSourWGS = osr.CoordinateTransformation(source, wgs84)\n","    transWGSSour = osr.CoordinateTransformation(wgs84, source)\n","    # transformando los puntos de los recortes a hacer\n","    xAI, yAI, _ = transWGSSour.TransformPoint(LonAI, LatAI) # arriba izq v2\n","    xAD, yAD, _ = transWGSSour.TransformPoint(LonAD, LatAD)  # abajo der v2\n","\n","    #print(xAI, yAI, xAD, yAD)\n","    return xAI, yAI, xAD, yAD\n","\n","#################\n","def cornerPointsToSHP(outputName, xAI, yAI, xAD, yAD, EPSG=4326):\n","    finalPolygonList = []\n","    polygon = Polygon([(xAI, yAI),\n","                      (xAI, yAD),\n","                      (xAD, yAD),\n","                      (xAD, yAI),\n","                      (xAI, yAI)])\n","    finalPolygonList.append(polygon)\n","\n","    # Define a polygon feature geometry with one attribute\n","    polygonsToSHP(outputName, '.shp', finalPolygonList, EPSG=EPSG)\n","\n","def polygonsToSHP(nameOutputSHP, SHPExtension, finalPolygonList, EPSG=4326):\n","    schema = {\n","        'geometry': 'Polygon',\n","        'properties': {'id': 'int'},\n","    }\n","    # Se crea un fichero SHP en el que se almacenan los polygon\n","    outFile = fiona.open(nameOutputSHP+SHPExtension, mode = 'w', crs=from_epsg(EPSG), driver='ESRI Shapefile', schema=schema)\n","    for index, poly in enumerate(finalPolygonList):\n","        outFile.write({\n","            'geometry':mapping(poly),\n","            'properties': {\n","                'id': index\n","            },\n","        })\n","    outFile.close()\n","\n","####################\n","# Unir Shapefiles de detecciones LiDAR en uno solo\n","def mergeSHPs(nameOutputSHP, folderOrigSHP, SHPExtension=\".shp\"):\n","  # Open polygon layer and create list of with all the Polygons\n","  polyList = []\n","  polyProperties = []\n","\n","  for filename in os.listdir(folderOrigSHP):\n","    if filename.endswith(SHPExtension):\n","      #print(filename)\n","      polyShp = fiona.open(folderOrigSHP+\"/\"+filename)\n","      for poly in polyShp:\n","        polyGeom = poly['geometry']['coordinates'][0]\n","        polyList.append(polyGeom)\n","\n","  # Se crea la transformación a WGS84\n","  epsgSHP = polyShp.meta['crs']['init'] # Extraer el EPSG con el ultimo SHP (deberían ser todos iguales)\n","  epsgSHP = epsgSHP.replace(\"epsg:\", \"\")\n","  source = osr.SpatialReference()\n","  source.ImportFromEPSG(int(epsgSHP))\n","  EPSG_wgs84 = 4326\n","  wgs84 = osr.SpatialReference()\n","  wgs84.ImportFromEPSG(EPSG_wgs84)\n","  transSourWGS = osr.CoordinateTransformation(source, wgs84)\n","\n","  # Se cogen todos los polígonos de cada fichero\n","  finalPolygonList = []\n","  for poly in polyList:\n","    auxPoly = []\n","    for point in poly:\n","      Lon, Lat, _ = transSourWGS.TransformPoint(point[0],point[1])\n","      a = (Lon, Lat)\n","      auxPoly.append(a)\n","    # Se genera un polígono (que cierra) del árbol detectado en WGS84\n","    polygon = Polygon(auxPoly)\n","    finalPolygonList.append(polygon)\n","\n","  # Export clipped polygons as shapefile\n","  polygonsToSHP(nameOutputSHP, SHPExtension, finalPolygonList, EPSG=EPSG_wgs84)\n","\n","#################\n","# \n","def TIFgetESPG(fileName):\n","  # Abro la imagen y extraigo su EPSG\n","  fileExtension = \".tif\"\n","  dem = gdal.Open(fileName+fileExtension)\n","  # Extraer el EPSG que modela las coordenadas\n","  EPSG   = osr.SpatialReference(wkt=dem.GetProjection()).GetAttrValue('AUTHORITY',1)\n","  dem   = None\n","  return int(EPSG)\n","\n","#################\n","def SHPgetESPG(SHPName, SHPExtension=\".shp\"):\n","  polyShp = fiona.open(SHPName+SHPExtension)\n","  epsgSHP = polyShp.meta['crs']['init']\n","  epsgSHP = epsgSHP.replace(\"epsg:\", \"\")\n","  return int(epsgSHP)\n","\n","#################\n","def cropTIFbySHP(TIFOriginalName, TIFOutputName, SHPName):\n","  EPSG = TIFgetESPG(TIFOriginalName)\n","  TIFExtension = \".tif\"\n","  SHPExtension = \".shp\"\n","\n","  # Cargo el SHP que define la zona a cortar\n","  with fiona.open(SHPName+SHPExtension, \"r\") as shapefile:\n","    shapes = [feature[\"geometry\"] for feature in shapefile]\n","\n","  # Abro la imagen y la corto con lo definido\n","  with rasterio.open(TIFOriginalName+TIFExtension) as src:\n","    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n","    out_meta = src.meta\n","    a = 'EPSG:'+str(EPSG)\n","    out_meta.update({\n","      \"driver\": \"GTiff\",\n","      \"height\": out_image.shape[1],\n","      \"width\": out_image.shape[2],\n","      \"transform\": out_transform,\n","      \"crs\": a\n","    })\n","\n","  # Guardo el corte\n","  with rasterio.open(TIFOutputName+TIFExtension, \"w\", **out_meta) as dest:\n","    dest.write(out_image)\n","\n","#################\n","def findMinMaxLatLonSHP(SHPName, SHPExtension=\".shp\"):\n","  # Identificar LatLon esquinas de todos los Shapefile, para definir el area del recorte a realizar\n","  minLat = 999\n","  minLon = 999\n","  maxLat =-999\n","  maxLon =-999\n","\n","  polyShp = fiona.open(SHPName)\n","  for poly in polyShp:\n","    polyGeom = poly['geometry']['coordinates'][0]\n","    for point in polyGeom:\n","      if minLat > point[1]:\n","        minLat = point[1]\n","      if point[1] > maxLat:\n","        maxLat = point[1]\n","      if minLon > point[0]:\n","        minLon = point[0]\n","      if point[0] > maxLon:\n","        maxLon = point[0]\n","\n","  return minLat, minLon, maxLat, maxLon\n","\n","#################\n","def TIFToPNG(filename):\n","  TIFExtension = \".tif\"\n","  PNGExtension = \".png\"\n","  img = cv2.imread(filename+TIFExtension)\n","  cv2.imwrite(filename+PNGExtension, img)\n","\n","#################\n","def XYPolygonToCSV(CSVName, TIFName, polyList, TIFExtension=\".tif\", CSVExtension=\".csv\"):\n","  with open(CSVName+CSVExtension, mode='w') as csv_write:\n","    csv_write = csv.writer(csv_write, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    csv_write.writerow(['image_path','xmin','ymin','xmax','ymax','label']) # Header\n","    for index, poly in enumerate(polyList):\n","      xAI = poly[0]\n","      yAI = poly[1]\n","      xAD = poly[2]\n","      yAD = poly[3]\n","\n","      # Los invierte para que esten bien colocadas las BB\n","      if xAI > xAD:\n","        a = xAD\n","        b = xAI\n","        xAD = b\n","        xAI = a\n","      if yAI > yAD:\n","        a = yAD\n","        b = yAI\n","        yAD = b\n","        yAI = a\n","      csv_write.writerow([TIFName+TIFExtension, xAI, yAI, xAD, yAD, 'Tree'])\n","\n","#################\n","def BBtoTIFpixel(polyList, SHPEPSG, TIFName, CSVName, TIFExtension=\".tif\", CSVExtension=\".csv\"):\n","  # Abro la foto en la que quiero extraer las posiciones\n","  dem = gdal.Open(TIFName+TIFExtension)\n","  EPSG = TIFgetESPG(TIFName)\n","  print(\"Imagen EPSG: \", str(EPSG))\n","\n","  source = osr.SpatialReference()\n","  source.ImportFromEPSG(int(EPSG))\n","  EPSG_wgs84 = SHPEPSG\n","  wgs84 = osr.SpatialReference()\n","  wgs84.ImportFromEPSG(EPSG_wgs84)\n","  transSourWGS = osr.CoordinateTransformation(source, wgs84)\n","  transWGSSour = osr.CoordinateTransformation(wgs84, source)\n","\n","  # Cada detección a pixel\n","  newPolyList = []\n","  for index, poly in enumerate(polyList): # Cada poligono\n","    #print(poly)\n","    newPolyX = []\n","    newPolyY = []\n","    for polyVertex in poly:             # cada vértice del polígono\n","      #print(polyVertex)\n","      # Lo transformo a las EPSG de la TIF\n","      xTIF, yTIF, _ = transWGSSour.TransformPoint(polyVertex[0], polyVertex[1])\n","      #print(xTIF, yTIF)\n","      # Hace lo mismo que lo de arriba\n","      #with rasterio.open(TIFName+TIFExtension) as src:\n","      #    rows, cols = rasterio.transform.rowcol(src.transform, x, y)\n","      # Y finalmente a Lat, Lon\n","      x, y = world_to_pixel(dem.GetGeoTransform(), xTIF, yTIF)\n","      #print(x, y)\n","      newPolyX.append(x)\n","      newPolyY.append(y)\n","\n","    newPolyX = list(set(newPolyX)) # Pilla los unique\n","    newPolyY = list(set(newPolyY))\n","\n","    if len(newPolyX) == 1: # Si solo hay 1, es que esta mal la BB\n","      continue\n","    if len(newPolyY) == 1:\n","      continue\n","\n","    # Los coloca correctamente para una BB\n","    if newPolyX[0] > newPolyX[1]:\n","      xAI = newPolyX[1]\n","      xAD = newPolyX[0]\n","    else:\n","      xAI = newPolyX[0]\n","      xAD = newPolyX[1]\n","    if newPolyY[0] > newPolyY[1]:\n","      yAI = newPolyY[1]\n","      yAD = newPolyY[0]\n","    else:\n","      yAI = newPolyY[0]\n","      yAD = newPolyY[1]\n","\n","    newPolyList.append([xAI, yAI, xAD, yAD])\n","\n","  return newPolyList\n","\n","#################\n","def SHPtoCSV(SHPName, TIFName, CSVName, SHPExtension=\".shp\", TIFExtension=\".tif\", CSVExtension=\".csv\"):\n","  print(\"SHPtoCSV\")\n","  #open polygon layer and create list of Polygons\n","  SHP_ESPG = SHPgetESPG(SHPName, SHPExtension)\n","  polyList = SHPgetPolygons(SHPName, SHPExtension)\n","  print(len(polyList))\n","  print(\"SHP EPSG: \", str(SHP_ESPG))\n","  # Pasa los poligonos a XY de la imagen dada\n","  newPolyList = BBtoTIFpixel(polyList, SHP_ESPG, TIFName, CSVName, TIFExtension, CSVExtension)\n","  # Escritura a CSV¿?\n","  print(len(newPolyList))\n","  XYPolygonToCSV(CSVName, TIFName, newPolyList, TIFExtension, CSVExtension)\n","\n","###################\n","def deepForestToSHP(trained_model_boxes, TIFName, SHPOutputName, SHPExtension=\".shp\", TIFExtension=\".tif\"):\n","  # Se transforman a WGS84\n","  EPSG_wgs84 = 4326\n","  ds = gdal.Open(TIFName+TIFExtension)\n","  _t = build_transform_inverse(ds, EPSG_wgs84) # WGS84\n","\n","  # Generacion de los poligonos \n","  finalPolygonList = []\n","  for index, BB in trained_model_boxes.iterrows():\n","    auxPoly = []\n","    xAI = BB[\"xmin\"]\n","    xAD = BB[\"xmax\"]\n","    yAI = BB[\"ymin\"]\n","    yAD = BB[\"ymax\"]\n","\n","    coordinates = find_spatial_coordinate_from_pixel(ds, _t, xAI,yAI)\n","    auxPoly.append( coordinates )\n","    coordinates = find_spatial_coordinate_from_pixel(ds, _t, xAI,yAD)\n","    auxPoly.append( coordinates )\n","    coordinates = find_spatial_coordinate_from_pixel(ds, _t, xAD,yAD)\n","    auxPoly.append( coordinates )\n","    coordinates = find_spatial_coordinate_from_pixel(ds, _t, xAD,yAI)\n","    auxPoly.append( coordinates )\n","    coordinates = find_spatial_coordinate_from_pixel(ds, _t, xAI,yAI)\n","    auxPoly.append( coordinates )\n","    # Se genera un polígono (que cierra) del árbol detectado en WGS84\n","    polygon = Polygon(auxPoly)\n","    finalPolygonList.append(polygon)\n","\n","  # Export clipped polygons as shapefile\n","  polygonsToSHP(SHPOutputName, SHPExtension, finalPolygonList, EPSG=EPSG_wgs84)"]},{"cell_type":"markdown","metadata":{"id":"JDBQZvS1hyn1"},"source":["# Merge SHP LiDAR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZeRZhFBhyTW","vscode":{"languageId":"python"}},"outputs":[],"source":["# JUNTA TODOS LOS SHP LIDAR (LOS ARBOLES DETECTADOS DE R) EN UN UNICO SHP PARA TENERLOS TODOS JUNTOS\n","# USO COLMENOUC3M PORQUE EN ALGUNA CARPETA ESTAN TODOS LOS SHP MENOS EL DEL CAMPUS\n","\n","# Unión SHP SIN la zona de la UC3M\n","mergeSHPs(\"Train/Train\", \"LiDAR_Detections/LiDAR_Detections_for_Training/\")\n","\n","# Unión SHP CON la zona de la UC3M\n","mergeSHPs(\"Example/Example\", \"LiDAR_Detections/LiDAR_Detections_for_Example/\")"]},{"cell_type":"markdown","metadata":{"id":"3wThOKZZDtCx"},"source":["# Clean LiDAR detections with OSM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2_3j5ASt3xD","vscode":{"languageId":"python"}},"outputs":[],"source":["###########\n","# Limpieza de SHP si coinciden un porcentaje con otros SHP (edificios, carreteras...)\n","# Apunta los que eliminaría en un CSV, porque tarda mucho y lo mismo peta\n","###########\n","def cleanSHPOverlappingRoadCSV(cleanSHP, cleanPath, roadSHP, roadPath, SHPExtension=\".shp\", threshold=25):\n","  # Abre ambos SHP\n","  polygonsToClean = SHPgetPolygons(cleanPath+cleanSHP, SHPExtension)\n","  polygonsRoads   = SHPgetPolygons(roadPath+roadSHP, SHPExtension)\n","  polygonsRoads = polygonsRoads[0]\n","  cleanEPSG = SHPgetESPG(cleanPath+cleanSHP)\n","  roadEPSG  = SHPgetESPG(roadPath+roadSHP)\n","\n","  # Crea un fichero donde va a apuntando por orden cuales elimina\n","  f = open(cleanPath+\"DeletedRoadsDetections.txt\", \"a\")\n","  for idx, polyClean in enumerate(polygonsToClean): # Por cada poligono a limpiar\n","    if idx <= 0:     # Para continuar desde donde terminó. COLOCARLO A MANO\n","      continue\n","    if idx%500 == 0:  # Para limpiar un poco el output del Colab y que no vaya como la mierda\n","      output.clear()\n","      f.close()       # Cierra para que se guarde en el CSV cada cierto tiempo\n","      f = open(cleanPath+\"DeletedRoadsDetections.txt\", \"a\")\n","    if idx%10 == 0:   # Para imprimir menos\n","      print(idx, \"de\", len(polygonsToClean))\n","\n","    checkAllOSM = True\n","    p1 = polygonToWGS84(polyClean, cleanEPSG) # Se transforma de array y como estuviese, a WGS84 y a Polygon\n","    for polyRoads in polygonsRoads:           # Por cada carretera [0]\n","      p2 = polygonToWGS84(polyRoads[0], roadEPSG)\n","      overlapDetected   = getOverlapPercentage(p1, p2) # Interseca con la carretera\n","      if overlapDetected > threshold: # Si supera un threshold, este polígono al carrer\n","        intersectsRoad = True\n","        for idx2 in range(1,len(polyRoads)): # Se mira el resto de huecos del poligono de la carretera\n","          # se hace la intersección de la detección a este hueco\n","          p3 = polygonToWGS84(polyRoads[idx2], roadEPSG)\n","          overlapDetected2 = getOverlapPercentage(p1, p3) # Interseca con la carretera\n","          if overlapDetected2 > threshold: # Si supera un threshold, está más dentro del hueco que de la carretera, luego no se elimina\n","            intersectsRoad = False\n","            break\n","        # Al mirar todos los huecos de esta carretera, sigue dentro, se elimina\n","        if intersectsRoad == True:\n","          print(\"hecho a: \", idx)\n","          f.write(str(idx)+\"\\n\")\n","\n","###########\n","# Limpieza de SHP si coinciden un porcentaje con otros SHP (edificios, carreteras...)\n","# Escribe los polígonos MENOS LOS DEL CSV en un nuevo SHP\n","###########\n","def cleanSHPCSVtoSHP(cleanSHP, cleanPath, inputCSV, outputName, SHPExtension=\".shp\"):\n","  # Abre ambos SHP\n","  polygonsToClean = SHPgetPolygons(cleanPath+cleanSHP, SHPExtension)\n","  cleanEPSG       = SHPgetESPG(cleanPath+cleanSHP)\n","  # Lectura del txt\n","  array = []\n","  with open(cleanPath+inputCSV) as f:\n","    for line in f:\n","      #print(line)\n","      array.append(int(line))\n","  # Pilla todos los polygons\n","  newPolyList = []\n","  for idx, polyClean in enumerate(polygonsToClean): # Por cada poligono a limpiar\n","    if idx%5000 == 0:  # Para limpiar un poco el output del Colab y que no vaya como la mierda\n","      output.clear()\n","    if idx%500 == 0:   # Para imprimir menos\n","      print(idx, \"de\", len(polygonsToClean))\n","    p1 = polygonToWGS84(polyClean, cleanEPSG) # Se transforma de array y como estuviese, a WGS84 y a Polygon\n","    if not idx in array: # Si no ha entrado petado con ninguno, se escribe, no overlapea\n","      newPolyList.append(p1)\n","  # Escribe los polígonos almacenados en un SHP\n","  polygonsToSHP(cleanPath+outputName, SHPExtension, newPolyList, EPSG=4326)\n","\n","###########\n","# Limpieza de SHP si coinciden un porcentaje con otros SHP (edificios, carreteras...)\n","# Apunta los que eliminaría en un CSV, porque tarda mucho y lo mismo peta\n","###########\n","def cleanSHPOverlappingBuildingCSV(cleanSHP, cleanPath, buildingsSHP, buildingsPath, SHPExtension=\".shp\", threshold=25):\n","  # Abre ambos SHP\n","  polygonsToClean   = SHPgetPolygons(cleanPath+cleanSHP, SHPExtension)\n","  polygonsBuildings = SHPgetPolygons(buildingsPath+buildingsSHP, SHPExtension)\n","  cleanEPSG     = SHPgetESPG(cleanPath+cleanSHP)\n","  buildingsEPSG = SHPgetESPG(buildingsPath+buildingsSHP)\n","\n","  # Crea un fichero donde va a apuntando por orden cuales elimina\n","  f = open(cleanPath+\"DeletedBuildingsDetections.txt\", \"a\")\n","  for idx, polyClean in enumerate(polygonsToClean): # Por cada poligono a limpiar\n","    if idx <= 0:     # Para continuar desde donde terminó. COLOCARLO A MANO\n","      continue\n","    if idx%500 == 0:  # Para limpiar un poco el output del Colab y que no vaya como la mierda\n","      output.clear()\n","      f.close()       # Cierra para que se guarde en el CSV cada cierto tiempo\n","      f = open(cleanPath+\"DeletedBuildingsDetections.txt\", \"a\")\n","    if idx%10 == 0:   # Para imprimir menos\n","      print(idx, \"de\", len(polygonsToClean))\n","\n","    p1 = polygonToWGS84(polyClean, cleanEPSG) # Se transforma de array y como estuviese, a WGS84 y a Polygon\n","    for polyBuildings in polygonsBuildings:         # Por cada edificio\n","      p2 = polygonToWGS84(polyBuildings, buildingsEPSG)\n","      overlapDetected   = getOverlapPercentage(p1, p2) # Se calcula el porcentaje de overlap\n","      if overlapDetected > threshold: # Si supera un threshold, este polígono al carrer\n","        f.write(str(idx)+\"\\n\")\n","        break\n","  \n","###########\n","# Calcula el porcentaje de overlap de un polígono respecto a otro\n","###########\n","def getOverlapPercentage(p1, p2):\n","  overlapDetected   = p2.intersection(p1).area / p1.area * 100\n","  return overlapDetected\n","\n","###########\n","# Transforma un array a un polígono en un EPSG determinado\n","###########\n","def polygonToWGS84(originArray, originEPSG, destEPSG=4326):\n","  if originEPSG == destEPSG:\n","    transformed = []\n","    for point in originArray:\n","      transformed.append([point[0], point[1]])\n","  else:\n","    # Extraer el EPSG que modela las coordenadas\n","    source = osr.SpatialReference()\n","    source.ImportFromEPSG(int(originEPSG))\n","    # Transformación a WGS84\n","    wgs84 = osr.SpatialReference()\n","    wgs84.ImportFromEPSG(destEPSG)\n","    transSourWGS = osr.CoordinateTransformation(source, wgs84)\n","    transWGSSour = osr.CoordinateTransformation(wgs84, source)\n","    \n","    # transformando los puntos de los recortes a hacer\n","    transformed = []\n","    for point in originArray:\n","      xAI, yAI, _ = transSourWGS.TransformPoint(point[0], point[1]) # arriba izq v2\n","      transformed.append([xAI, yAI])\n","  b = Polygon(transformed)\n","  return b\n","\n","###########\n","# \n","###########\n","def SHPgetPolygons(SHPName, SHPExtension=\".shp\"):\n","  polyList = []\n","  with fiona.open(SHPName+SHPExtension) as polyShp:\n","    if len(polyShp) == 1:  # Es multiPolygon\n","      #print(\"Es multipolygon\")\n","      multiPol = polyShp[0]['geometry']['coordinates']\n","      #print(\"multiPol\", len(multiPol))\n","      newPoly = []\n","\n","      for b in multiPol:\n","        #print(\"b\", len(b))\n","        newPoly2 = []\n","        for c in b:\n","          #print(\"c\", len(c))\n","          newPoly2.append( c )\n","          #for d in c:  # Aqui ya siempre son 2, tuplas XY\n","          #  print(\"d\", len(d))   \n","        newPoly.append( newPoly2 )\n","      polyList.append( newPoly )\n","\n","    else: # Es polygon\n","      for poly in polyShp:\n","        polyGeom = poly['geometry']['coordinates']\n","        polyList.append(polyGeom[0])\n","      #return polyList\n","  \n","  return polyList"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LN0KLqI9ENhg","vscode":{"languageId":"python"}},"outputs":[],"source":["cleanSHPOverlappingBuildingCSV(\"Train\", \"Train/\", \"BuildingsWGS84\", \"To_Clean_LiDAR_Detections/\")\n","cleanSHPCSVtoSHP(\"Train\", \"Train/\", \"DeletedBuildingsDetections.txt\", \"Train_NoBuildings\")\n","\n","cleanSHPOverlappingRoadCSV(\"Train_NoBuildings\", \"Train/\", \"RoadsEPSG3345\", \"To_Clean_LiDAR_Detections/\")\n","cleanSHPCSVtoSHP(\"Train_NoBuildings\", \"Train/\", \"DeletedRoadsDetections.txt\", \"Train_NoBuildings_NoRoads\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIGpmrW5YH4P","vscode":{"languageId":"python"}},"outputs":[],"source":["cleanSHPOverlappingBuildingCSV(\"Example\", \"Example/\", \"BuildingsWGS84\", \"To_Clean_LiDAR_Detections/\")\n","cleanSHPCSVtoSHP(\"Example\", \"Example/\", \"DeletedBuildingsDetections.txt\", \"Example_NoBuildings\")\n","\n","cleanSHPOverlappingRoadCSV(\"Example_NoBuildings\", \"Example/\", \"RoadsEPSG3345\", \"To_Clean_LiDAR_Detections/\")\n","cleanSHPCSVtoSHP(\"Example_NoBuildings\", \"Example/\", \"DeletedRoadsDetections.txt\", \"Example_NoBuildings_NoRoads\")"]},{"cell_type":"markdown","metadata":{"id":"ZQzIDxJwhn10"},"source":["# SHP LiDAR detections related in a CSV with each pixel of the TIF image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C51gHgLYmvMm","vscode":{"languageId":"python"}},"outputs":[],"source":["# TENEMOS UN SHP CON MILES DE RECTANGULOS EN LAT LON (EN UN SISTEMA DE COORDENDAS CONCRETO. WGS84??).\n","# LOS CONVERTIMOS A PIXELES EN LA ORTOFOTO RECORTADA DE COLME\n","# Pasamos las detecciones del LiDAR a un CSV para entrenar la ortofoto seleccionada\n","#EJ. PARA EL ARBOL EN LAT LONG X, LE CORRESPONDE EN LA IMAGEN DADA EL PIXEL Y\n","csv_train = \"Train/Train_CSV_annotations/CSV_ALL_ORTHOPHOTO_annotations\"\n","SHPtoCSV(\"Train/Train_NoBuildings_NoRoads\", tif_image, csv_train)\n"]},{"cell_type":"markdown","metadata":{"id":"atPtDvpkD7Ge"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYM6pRXc1O2H","vscode":{"languageId":"python"}},"outputs":[],"source":["###################\n","def cropsDeepForest(TIFName, CSVName, trainTest, nameOutputModel, TIFExtension=\".tif\", CSVExtension=\".csv\", modelExtension=\".h5\"):\n","    # Lectura del CSV original\n","    dataset_annotations = pd.read_csv(CSVName+CSVExtension)\n","    # División de la imagen completa en trozos de 400x400 para entrenar\n","    cropsFolder = 'Train/Train_CSV_annotations/CROPS,NET_INPUTS'\n","    print(TIFName+TIFExtension)\n","    train_annotations = preprocess.split_raster(CSVName+CSVExtension, path_to_raster=TIFName+TIFExtension, \n","                                                patch_size=400, base_dir=cropsFolder, patch_overlap=0.05)\n","    print(\"División en imágenes 400x400 completada\")\n","    return train_annotations\n","\n","def trainDeepForest(train_annotations, CSVName, trainTest, nameOutputModel, TIFExtension=\".tif\", CSVExtension=\".csv\", modelExtension=\".h5\"):\n","    # División del CSV completo en Train-Test para que aprenda la red\n","    image_dir = train_annotations.image_path.unique()\n","    print(image_dir)\n","    test_dir  = np.random.choice(image_dir, trainTest[1]) # Porcentaje test\n","    test_annotations  = train_annotations.loc[ train_annotations.image_path.isin(test_dir)]\n","    train_annotations = train_annotations.loc[~train_annotations.image_path.isin(test_dir)]\n","    #train_annotations.head() # impresion principio tabla\n","    #print(\"There are {} training crown annotations\".format(train_annotations.shape[0]))\n","    #print(\"There are {} test crown annotations\".format(test_annotations.shape[0]))\n","    print(\"División CSV train-test completada\")\n","\n","    cropsFolder = 'Train/Train_CSV_annotations/CROPS,NET_INPUTS/'\n","    # Genera ambos CSV\n","    filenameTrain = cropsFolder+\"train\"+nameOutputModel+CSVExtension\n","    filenameTest  = cropsFolder+\"test\"+nameOutputModel+CSVExtension\n","    train_annotations.to_csv(filenameTrain, index=False, header=False)\n","    test_annotations.to_csv( filenameTest,  index=False, header=False)\n","\n","    ##### Creacion del modelo\n","    model = deepforest.deepforest() # Crea un modelo nuevo\n","    model.config[\"gpus\"] = 1 # Para utilizar la GPU de Google Colab (activarla first)\n","    model.config[\"epochs\"] = 5\n","    model.config[\"save-snapshot\"] = True\n","    print(\"A generar modelo\")\n","    model.train(annotations=filenameTrain, input_type=\"fit_generator\") #ENTRENAMIENTO MODELO CON CONJUNTO DE ENTRENAMIENTO\n","    print(\"Modelo entrenado, guardando\")\n","    #model.evaluate_generator(filenameTrain) #EVALUACIÓN DEL NUEVO MODELO MODELO: ACIERTO 60%\n","    model.model.save('Model/'+nameOutputModel+modelExtension) #GUARDAMOS EL MODELO\n","\n","# guardar las anotaciones en CSV\n","def annotationsToCSV(name, train_annotations):\n","  train_annotations.to_csv(name+'_annotations.csv')\n","\n","# cargar las anotaciones en CSV en el mismo objeto Pandas Dataframe\n","def loadCSVannotations(name):\n","  aa = pd.read_csv(name+'_annotations.csv')\n","  aa = aa.drop(aa.columns[[0]], axis=1)\n","  return aa"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"elapsed":250,"status":"error","timestamp":1655279641327,"user":{"displayName":"LAZARO FORNIS HERRANZ","userId":"12453935234529602211"},"user_tz":-120},"id":"p3rpEjk6dPyY","outputId":"e7263ddd-a58d-4aa2-ab67-54021a4ea148","vscode":{"languageId":"python"}},"outputs":[],"source":["# Entrenando campusNotBad\n","modelName='model'\n","#haveCSV = False\n","haveCSV = True\n","if haveCSV == True: # Carga las anotaciones directamente de un CSV, en vez de calcularlas y hacer todos los crop de nuevo\n","  train_annotations = loadCSVannotations('Train/Train_CSV_annotations/CSV_ORTHOPHOTO_CROPS')\n","else:\n","  Image.MAX_IMAGE_PIXELS = 337351030\n","  train_annotations = cropsDeepForest(tif_image, 'Train/Train_CSV_annotations/CSV_ALL_ORTHOPHOTO_annotations', [70, 30], modelName)\n","  annotationsToCSV('Train/Train_CSV_annotations/CSV_ORTHOPHOTO_CROPS', train_annotations) # Guarda las anotaciones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMg7uoNP-HQO","vscode":{"languageId":"python"}},"outputs":[],"source":["#print(train_annotations.image_path)\n","trainDeepForest(train_annotations, csv_train, [70, 30], modelName)"]},{"cell_type":"markdown","metadata":{"id":"t2AWXL0lRuZM"},"source":["# Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"executionInfo":{"elapsed":386,"status":"error","timestamp":1655279612754,"user":{"displayName":"LAZARO FORNIS HERRANZ","userId":"12453935234529602211"},"user_tz":-120},"id":"xRhxooZNV_c9","outputId":"eef26bf3-a7bd-4103-b71c-ff29dd3e8d4f","vscode":{"languageId":"python"}},"outputs":[],"source":["modelName='model'\n","# Cargar modelo entrenado\n","model = deepforest.deepforest(saved_model='Model/'+modelName+'.h5')\n","\n","#PRREDICCION CON EL NUEVO MODELO\n","trained_model_boxes = model.predict_tile(\"Orthophoto_University_Example.tif\", return_plot=True)\n","\n","#VISUALIZACION RESULTADOS, CLARAMENTE MEJORA RESPECTO AL MODELO DEFAULT, PARA SOLO TENER 1500 INSTANCIAS Y 1 EPOCA ESTA MUY BIEN\n","fig = plt.figure(figsize=(20,20))\n","plt.imshow(trained_model_boxes)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"elapsed":225,"status":"error","timestamp":1655279607470,"user":{"displayName":"LAZARO FORNIS HERRANZ","userId":"12453935234529602211"},"user_tz":-120},"id":"MwbLMBAoDP7v","outputId":"2769d8dc-a667-4792-f325-e794395ed3fc","vscode":{"languageId":"python"}},"outputs":[],"source":["# Predicción\n","trained_model_boxes = model.predict_tile(\"Orthophoto_University_Example.tif\", return_plot=False, patch_overlap=0.2,iou_threshold=0.2)\n","# Create SHP\n","deepForestToSHP(trained_model_boxes, TIFName=\"Orthophoto_University_Example\", SHPOutputName='Example/net_detections')\n","# Create CSV\n","SHPtoCSV(SHPName='Example/net_detections', TIFName=\"Orthophoto_University_Example\",CSVName='Example/net_detections_CSV_annotations')"]},{"cell_type":"markdown","metadata":{"id":"WZgFfoFVEAz7"},"source":["# Analysis of the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzlLxDPx5MPt","vscode":{"languageId":"python"}},"outputs":[],"source":["\n","def calculatePolygonArea(polygonVec):\n","  geod = Geod(ellps=\"WGS84\") # specify a named ellipsoid\n","  poly = Polygon(polygonVec)\n","  area = abs(geod.geometry_area_perimeter(poly)[0])\n","  print('# Geodesic area: {:.3f} m^2'.format(area))\n","  return area\n","\n","def calculateSHPAreas(SHPName, TIFName, CSVName, SHPExtension=\".shp\", TIFExtension=\".tif\", CSVExtension=\".csv\"):\n","  SHP_ESPG = SHPgetESPG(SHPName, SHPExtension)\n","  polyList = SHPgetPolygons(SHPName, SHPExtension)\n","\n","  arrArea = []\n","  for poly in polyList:\n","    a = calculatePolygonArea(poly)\n","    arrArea.append(a)\n","  \n","  return arrArea"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Eh1FN3wGIzb","vscode":{"languageId":"python"}},"outputs":[],"source":["\n","raw_symbols = SymbolValidator().values\n","\n","symbols = []\n","for i in range(0,len(raw_symbols),3):\n","    symbols.append(raw_symbols[i])\n","colors = px.colors.qualitative.Dark24"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":658},"executionInfo":{"elapsed":245,"status":"error","timestamp":1655279595374,"user":{"displayName":"LAZARO FORNIS HERRANZ","userId":"12453935234529602211"},"user_tz":-120},"id":"kw4LcE2REAM-","outputId":"1293d81a-a702-4081-b598-cf2eebd17bac","vscode":{"languageId":"python"}},"outputs":[],"source":["############################\n","# Extraer las dimensiones medias de cada bounding-box\n","\n","# Create CSV\n","SHPtoCSV(SHPName='Example/Test_NoBuildings_NoRoads', TIFName=\"Orthophoto_University_Example\",CSVName='Example/Test_NoBuildings_NoRoads_CSV_annotations')\n","\n","shp_test = \"Example/Test_NoBuildings_NoRoads\" # LiDAR\n","csv_test = \"Example/Test_NoBuildings_NoRoads_CSV_annotations\"\n","tif_image = \"Orthophoto_University_Example\"\n","lidarAreas = calculateSHPAreas(shp_test, tif_image, csv_test)\n","\n","shp_result = \"Example/net_detections\"\n","csv_result = \"Example/net_detections_CSV_annotations\"\n","imageAreas = calculateSHPAreas(shp_result, tif_image, csv_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKaAE2TMHLxM","vscode":{"languageId":"python"}},"outputs":[],"source":["colors = px.colors.qualitative.T10\n","\n","############## CADA SEGMENTATOR POR SEPARADO\n","fig = go.Figure()\n","\n","#aa = [\"LiDAR\"] * len(a)\n","fig.add_trace(\n","    go.Box(\n","        name=\"LiDAR\",\n","        x=lidarAreas,\n","        #boxmean='sd', # True represent mean; 'sd' represent mean and standard deviation\n","    )\n",")\n","#aa = [\"Imagery\"] * len(a)\n","fig.add_trace(\n","    go.Box(\n","        name=\"Imagery\",\n","        x=imageAreas,\n","        #boxmean='sd', # True represent mean; 'sd' represent mean and standard deviation\n","    )\n",")\n","\n","fig.update_layout(\n","    legend=dict(\n","        traceorder=\"normal\",\n","        font=dict(\n","            size=14,\n","            color=\"black\"\n","        ),\n","        bordercolor=\"Black\",\n","        borderwidth=1,\n","        xanchor = \"center\", # Para centrarla horizontalmente\n","        x = 0.5,            # Para centrarla horizontalmente\n","        orientation=\"h\",    # Para centrarla horizontalmente\n","    ),\n","    autosize=False,\n","    width=1400,\n","    height=450,\n","    # figure layout adjustments\n","    #boxmode='group',\n","    #xaxis_tickangle=0,\n",")\n","fig.update_xaxes(range=[0, 100])\n","fig.show() # Para que salga el resultado\n","\n","outputFile         = F\"./percentOverlap.svg\" # svg                   # output file\n","pio.write_image(fig, outputFile) # Se guarda el diagrama en la carpeta de Drive / local"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Script.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
